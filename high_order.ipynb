{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import argparse\n",
    "from data.cifar import CIFAR10\n",
    "from data.datasets import input_dataset\n",
    "from hoc import *\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m train_dataset, test_dataset, num_classes, num_training_samples, num_testing_samples \u001B[38;5;241m=\u001B[39m \u001B[43minput_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcifar10\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mnoise_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minstance\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mnoise_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m model \u001B[38;5;241m=\u001B[39m res_cifar\u001B[38;5;241m.\u001B[39mresnet18(pretrained\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m param \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mparameters():\n",
      "File \u001B[0;32m~/PycharmProjects/HOC/data/datasets.py:35\u001B[0m, in \u001B[0;36minput_dataset\u001B[0;34m(dataset, noise_type, noise_ratio, transform, noise_file)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minput_dataset\u001B[39m(dataset, noise_type, noise_ratio, transform \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m, noise_file \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m dataset \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcifar10\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m---> 35\u001B[0m         train_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mCIFAR10\u001B[49m\u001B[43m(\u001B[49m\u001B[43mroot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m./data/\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     36\u001B[0m \u001B[43m                                \u001B[49m\u001B[43mdownload\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\n\u001B[1;32m     37\u001B[0m \u001B[43m                                \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     38\u001B[0m \u001B[43m                                \u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtrain_cifar10_transform\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtest_cifar10_transform\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     39\u001B[0m \u001B[43m                                \u001B[49m\u001B[43mnoise_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnoise_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[43m                                \u001B[49m\u001B[43mnoise_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnoise_ratio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     41\u001B[0m \u001B[43m                                \u001B[49m\u001B[43mnoise_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnoise_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[43m                           \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     43\u001B[0m         test_dataset \u001B[38;5;241m=\u001B[39m CIFAR10(root\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./data/\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     44\u001B[0m                                 download\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,  \n\u001B[1;32m     45\u001B[0m                                 train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     48\u001B[0m                                 noise_rate\u001B[38;5;241m=\u001B[39mnoise_ratio\n\u001B[1;32m     49\u001B[0m                           )\n\u001B[1;32m     50\u001B[0m         num_classes \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m\n",
      "File \u001B[0;32m~/PycharmProjects/HOC/data/cifar.py:107\u001B[0m, in \u001B[0;36mCIFAR10.__init__\u001B[0;34m(self, root, train, transform, target_transform, download, noise_type, noise_rate, random_state, noise_file)\u001B[0m\n\u001B[1;32m    105\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnoise_or_not \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_noisy_labels)\u001B[38;5;241m!=\u001B[39mnp\u001B[38;5;241m.\u001B[39mtranspose(_train_labels)\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m noise_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minstance\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m--> 107\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_noisy_labels, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactual_noise_rate \u001B[38;5;241m=\u001B[39m \u001B[43mnoisify_instance\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43mnoise_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnoise_rate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    108\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mover all noise rate is \u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactual_noise_rate)\n\u001B[1;32m    109\u001B[0m     \u001B[38;5;66;03m#self.train_noisy_labels=[i[0] for i in self.train_noisy_labels]\u001B[39;00m\n\u001B[1;32m    110\u001B[0m     \u001B[38;5;66;03m#self.train_noisy_labels=[i[0] for i in self.train_noisy_labels]\u001B[39;00m\n\u001B[1;32m    111\u001B[0m     \u001B[38;5;66;03m#_train_labels=[i[0] for i in self.train_labels]\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/HOC/data/utils.py:205\u001B[0m, in \u001B[0;36mnoisify_instance\u001B[0;34m(train_data, train_labels, noise_rate)\u001B[0m\n\u001B[1;32m    203\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, sample \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_data):\n\u001B[1;32m    204\u001B[0m     sample \u001B[38;5;241m=\u001B[39m sample\u001B[38;5;241m.\u001B[39mflatten()\n\u001B[0;32m--> 205\u001B[0m     p_all \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatmul\u001B[49m\u001B[43m(\u001B[49m\u001B[43msample\u001B[49m\u001B[43m,\u001B[49m\u001B[43mw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    206\u001B[0m     p_all[train_labels[i]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1000000\u001B[39m\n\u001B[1;32m    207\u001B[0m     p_all \u001B[38;5;241m=\u001B[39m q[i]\u001B[38;5;241m*\u001B[39m F\u001B[38;5;241m.\u001B[39msoftmax(torch\u001B[38;5;241m.\u001B[39mtensor(p_all),dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mnumpy()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset, num_classes, num_training_samples, num_testing_samples = input_dataset('cifar10',noise_type=\"instance\",noise_ratio=0.2)\n",
    "model = res_cifar.resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "model.to(\"mps\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataloader_EF = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                      batch_size=128,\n",
    "                                                      shuffle=True,\n",
    "                                                      num_workers=2,\n",
    "                                                      drop_last=False)\n",
    "# model.to(\"mps\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "\n",
    "def count_real_high(KINDS, T, P, mode, _device = 'cpu'):\n",
    "    # time1 = time.time()\n",
    "    P = P.reshape((KINDS, 1))\n",
    "    p_real = [[] for _ in range(4)]\n",
    "\n",
    "    p_real[0] = torch.mm(T.transpose(0, 1), P).transpose(0, 1)\n",
    "    #print(p_real[0].shape)\n",
    "    # p_real[2] = torch.zeros((KINDS, KINDS, KINDS)).to(_device)\n",
    "    p_real[2] = torch.zeros((KINDS, KINDS, KINDS))\n",
    "    p_real[3] = torch.zeros((KINDS, KINDS, KINDS,KINDS))\n",
    "\n",
    "    temp33 = torch.tensor([])\n",
    "    for i in range(KINDS):\n",
    "        Ti = torch.cat((T[:, i:], T[:, :i]), 1)\n",
    "        temp2 = torch.mm((T * Ti).transpose(0, 1), P)#T * R1 * P\n",
    "        p_real[1] = torch.cat([p_real[1], temp2], 1) if i != 0 else temp2 #P real[preal,  T * R1 * P]\n",
    "\n",
    "        for j in range(KINDS):\n",
    "            Tj = torch.cat((T[:, j:], T[:, :j]), 1)\n",
    "            temp3 = torch.mm((T * Ti * Tj).transpose(0, 1), P)\n",
    "            temp33 = torch.cat([temp33, temp3], 1) if j != 0 else temp3\n",
    "\n",
    "\n",
    "            for k in range(KINDS):\n",
    "                Tk = torch.cat((T[:, k:], T[:, :k]), 1)\n",
    "                temp4 = torch.mm((T * Ti * Tj*Tk).transpose(0, 1), P)\n",
    "                temp44 = torch.cat([temp44, temp4], 1) if k != 0 else temp4\n",
    "            t4 = []\n",
    "\n",
    "            for p4 in range(KINDS):\n",
    "                t4 = torch.cat((temp44[p4, KINDS - p4:], temp44[p4, :KINDS - p4]))\n",
    "                temp44[p4] = t4\n",
    "\n",
    "            for r in range(KINDS):\n",
    "                p_real[3][r][(i+r+KINDS)%KINDS][(i+r+j+KINDS)%KINDS] = temp44[r]\n",
    "\n",
    "\n",
    "        # adjust the order of the output (N*N*N), keeping consistent with p_estimate\n",
    "        t3 = []\n",
    "        for p3 in range(KINDS):\n",
    "            t3 = torch.cat((temp33[p3, KINDS - p3:], temp33[p3, :KINDS - p3]))\n",
    "            temp33[p3] = t3\n",
    "        for r in range(KINDS):\n",
    "            p_real[2][r][(i+r+KINDS)%KINDS] = temp33[r]\n",
    "\n",
    "\n",
    "    temp = []       # adjust the order of the output (N*N), keeping consistent with p_estimate\n",
    "    for p1 in range(KINDS):\n",
    "        temp = torch.cat((p_real[1][p1, KINDS-p1:], p_real[1][p1, :KINDS-p1]))\n",
    "        p_real[1][p1] = temp\n",
    "    return p_real\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def func_high(KINDS, p_estimate, T_out, P_out, N,step, LOCAL, _device):\n",
    "    eps = 1e-2\n",
    "    eps2 = 1e-8\n",
    "    eps3 = 1e-5\n",
    "    loss = torch.tensor(0.0).to(_device)       # define the loss\n",
    "\n",
    "    P = smp(P_out)\n",
    "    T = smt(T_out)\n",
    "\n",
    "    mode = random.randint(0, KINDS-1)\n",
    "    mode = -1\n",
    "    # Borrow p_ The calculation method of real is to calculate the temporary values of T and P at this time: N, N*N, N*N*N\n",
    "    p_temp = count_real_high(KINDS, T.to(torch.device(\"cpu\")), P.to(torch.device(\"cpu\")), mode, _device)\n",
    "\n",
    "    weight = [1.0,1.0,.0,1.0]\n",
    "    # weight = [2.0,1.0,1.0]\n",
    "    order = [0,1,3]\n",
    "    for j in range(4):  # || P1 || + || P2 || + || P3 ||\n",
    "        p_temp[j] = p_temp[j].to(_device)\n",
    "        loss += weight[j] * torch.norm(p_estimate[j] - p_temp[j]) #/ np.sqrt(N**j)\n",
    "\n",
    "    if step > 100 and LOCAL and KINDS != 100:\n",
    "        loss += torch.mean(torch.log(P+eps))/10\n",
    "\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calc_func_high(KINDS, p_estimate, LOCAL, _device, max_step = 501, T0=None, p0 = None, lr = 0.1):\n",
    "\n",
    "    N = KINDS\n",
    "    eps = 1e-8\n",
    "    if T0 is None:\n",
    "        T = 5 * torch.eye(N) - torch.ones((N,N))\n",
    "    else:\n",
    "        T = T0\n",
    "\n",
    "    if p0 is None:\n",
    "        P = torch.ones((N, 1), device = None) / N + torch.rand((N,1), device = None)*0.1     # Pï¼š0-9 distribution\n",
    "    else:\n",
    "        P = p0\n",
    "\n",
    "    T = T.to(_device)\n",
    "    P = P.to(_device)\n",
    "    p_estimate = [item.to(_device) for item in p_estimate]\n",
    "    print(f'using {_device} to solve equations')\n",
    "\n",
    "    T.requires_grad = True\n",
    "    P.requires_grad = True\n",
    "\n",
    "    optimizer = torch.optim.Adam([T, P], lr = lr)\n",
    "\n",
    "    # train\n",
    "    loss_min = 100.0\n",
    "    T_rec = torch.zeros_like(T)\n",
    "    P_rec = torch.zeros_like(P)\n",
    "\n",
    "    time1 = time.time()\n",
    "    for step in range(max_step):\n",
    "        if step:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        loss = func_high(KINDS, p_estimate, T, P, N,step, LOCAL, _device)\n",
    "        if loss < loss_min and step > 5:\n",
    "            loss_min = loss.detach()\n",
    "            T_rec = T.detach()\n",
    "            P_rec = P.detach()\n",
    "        if step % 100 == 0:\n",
    "            print('loss {}'.format(loss))\n",
    "            print(f'step: {step}  time_cost: {time.time() - time1}')\n",
    "            print(f'T {np.round(smt(T.cpu()).detach().numpy()*100,1)}', flush=True)\n",
    "            print(f'P {np.round(smp(P.cpu().view(-1)).detach().numpy()*100,1)}', flush=True)\n",
    "            time1 = time.time()\n",
    "\n",
    "    return loss_min, smt(T_rec).detach(), smp(P_rec).detach(), T_rec.detach()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "record = [[] for _ in range(num_classes)]\n",
    "for i_batch, (feature, label, index) in enumerate(train_dataloader_EF):\n",
    "    feature = feature.to(\"mps\")\n",
    "    label = label.to(\"mps\")\n",
    "    extracted_feature, _ = model(feature)\n",
    "    for i in range(extracted_feature.shape[0]):\n",
    "        record[label[i]].append({'feature': extracted_feature[i].detach().cpu(), 'index': index[i]})\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def count_y(KINDS, feat_cord, label, cluster_sum):\n",
    "    # feat_cord = torch.tensor(final_feat)\n",
    "    cnt = [[] for _ in range(4)]\n",
    "    cnt[0] = torch.zeros(KINDS)\n",
    "    cnt[1] = torch.zeros(KINDS, KINDS)\n",
    "    cnt[2] = torch.zeros(KINDS, KINDS, KINDS)\n",
    "    cnt[3] = torch.zeros(KINDS, KINDS, KINDS,KINDS)\n",
    "    feat_cord = feat_cord.cpu().numpy()\n",
    "    dist = distCosine(feat_cord, feat_cord)\n",
    "    max_val = np.max(dist)\n",
    "    am = np.argmin(dist,axis=1)\n",
    "    for i in range(cluster_sum):\n",
    "        dist[i][am[i]] = 10000.0 + max_val\n",
    "    min_dis_id = np.argmin(dist,axis=1)\n",
    "    for i in range(cluster_sum):\n",
    "        dist[i][min_dis_id[i]] = 10000.0 + max_val\n",
    "    min_dis_id2 = np.argmin(dist,axis=1)\n",
    "    for i in range(cluster_sum):\n",
    "        dist[i][min_dis_id2[i]] = 10000.0 + max_val\n",
    "    min_dis_id3 = np.argmin(dist,axis=1)\n",
    "    for x1 in range(cluster_sum):\n",
    "        cnt[0][label[x1]] += 1\n",
    "        cnt[1][label[x1]][label[min_dis_id[x1]]] += 1\n",
    "        cnt[2][label[x1]][label[min_dis_id[x1]]][label[min_dis_id2[x1]]] += 1\n",
    "        cnt[3][label[x1]][label[min_dis_id[x1]]][label[min_dis_id2[x1]]][label[min_dis_id3[x1]]] += 1\n",
    "\n",
    "    return cnt\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_T_global_high(num_class, record, max_step=501, T0=None, p0=None, lr=0.1, NumTest=50, all_point_cnt=15000):\n",
    "    total_len = sum([len(a) for a in record])\n",
    "    origin_trans = torch.zeros(total_len, record[0][0]['feature'].shape[0])\n",
    "    origin_label = torch.zeros(total_len).long()\n",
    "    cnt, lb = 0, 0\n",
    "    for item in record:\n",
    "        for i in item:\n",
    "            origin_trans[cnt] = i['feature']\n",
    "            origin_label[cnt] = lb\n",
    "            cnt += 1\n",
    "        lb += 1\n",
    "    data_set = {'feature': origin_trans, 'noisy_label': origin_label}\n",
    "\n",
    "    # Build Feature Clusters --------------------------------------\n",
    "    KINDS = num_class\n",
    "    # NumTest = 50\n",
    "    # all_point_cnt = 15000\n",
    "\n",
    "    p_estimate = [[] for _ in range(4)]\n",
    "    p_estimate[0] = torch.zeros(KINDS)\n",
    "    p_estimate[1] = torch.zeros(KINDS, KINDS)\n",
    "\n",
    "    p_estimate[2] = torch.zeros(KINDS, KINDS, KINDS)\n",
    "    p_estimate[3] = torch.zeros(KINDS, KINDS, KINDS,KINDS)\n",
    "    p_estimate_rec = torch.zeros(NumTest, 3)\n",
    "    for idx in range(NumTest):\n",
    "        print(idx, flush=True,end=\" \")\n",
    "        # global\n",
    "        sample = np.random.choice(range(data_set['feature'].shape[0]), all_point_cnt, replace=False)\n",
    "        # final_feat, noisy_label = get_feat_clusters(data_set, sample)\n",
    "        final_feat = data_set['feature'][sample]\n",
    "        noisy_label = data_set['noisy_label'][sample]\n",
    "        cnt_y_3 = count_y(KINDS, final_feat, noisy_label, all_point_cnt)\n",
    "        for i in range(4):\n",
    "            cnt_y_3[i] /= all_point_cnt\n",
    "            p_estimate[i] = p_estimate[i] + cnt_y_3[i] if idx != 0 else cnt_y_3[i]\n",
    "\n",
    "    for j in range(4):\n",
    "        p_estimate[j] = p_estimate[j] / NumTest\n",
    "\n",
    "\n",
    "    loss_min, E_calc, P_calc, T_init = calc_func_high(KINDS, p_estimate, False, \"mps\", max_step, T0, p0, lr=lr)\n",
    "\n",
    "    E_calc = E_calc.cpu().numpy()\n",
    "    T_init = T_init.cpu().numpy()\n",
    "    return E_calc, T_init\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_estimate_T, _ = get_T_global_high(num_class=num_classes,record=record,max_step=1500, lr=0.1, NumTest=50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.rint(new_estimate_T*100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[11., 12., 13.],\n         [ 0.,  0.,  0.],\n         [ 0.,  0.,  0.]],\n\n        [[ 0.,  0.,  0.],\n         [23., 21., 22.],\n         [ 0.,  0.,  0.]],\n\n        [[ 0.,  0.,  0.],\n         [ 0.,  0.,  0.],\n         [32., 33., 31.]]])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = np.array([[11,12,13],\n",
    "              [21,22,23],\n",
    "              [31,32,33]])\n",
    "T = torch.from_numpy(T)\n",
    "t3 = []\n",
    "p_real =  torch.zeros((3, 3, 3))\n",
    "for p3 in range(3):\n",
    "    t3 = torch.cat((T[p3, 3 - p3:], T[p3, :3 - p3]))\n",
    "    T[p3] = t3\n",
    "for r in range(3):\n",
    "    p_real[r][(0 + r + 3) % 3] = T[r]\n",
    "p_real"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}