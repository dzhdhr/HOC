{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import argparse\n",
    "from data.cifar import CIFAR10\n",
    "from data.datasets import input_dataset\n",
    "from hoc import *\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "[[79.2  0.  20.1  0.   0.   0.   0.1  0.1  0.4  0. ]\n",
      " [ 0.3 80.4  0.1  0.4  0.8  0.1  1.2  0.6  8.4  7.6]\n",
      " [ 8.4  0.  79.6  0.   0.  11.8  0.   0.   0.   0. ]\n",
      " [ 0.6  0.2  0.  80.2  1.1 11.4  6.1  0.1  0.   0.3]\n",
      " [ 0.   0.  15.7  0.2 79.   0.   0.1  4.5  0.   0.5]\n",
      " [ 0.   2.7  3.3  0.   0.  79.   0.8  0.2  0.1 13.9]\n",
      " [ 0.2  0.4 13.6  0.5  2.5  0.  78.7  0.   1.5  2.6]\n",
      " [ 6.7  0.   0.   0.2  0.8  0.   0.4 79.2 12.7  0. ]\n",
      " [ 0.   0.1  0.   5.7 14.5  0.   0.   0.  79.7  0. ]\n",
      " [ 0.   4.7  0.   0.2 15.8  0.1  0.   0.   0.3 78.9]]\n",
      "over all noise rate is  0.20611999999999997\n",
      "The noisy data ratio in each class is [0.09544 0.08862 0.13252 0.08738 0.1147  0.10246 0.08738 0.08468 0.1031\n",
      " 0.10372]\n",
      "Files already downloaded and verified\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Split: train\n",
      "    Root Location: ./data/\n",
      "    Transforms (if any): Compose(\n",
      "                             RandomCrop(size=(32, 32), padding=4)\n",
      "                             RandomHorizontalFlip(p=0.5)\n",
      "                             ToTensor()\n",
      "                             Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n",
      "                         )\n",
      "    Target Transforms (if any): None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CIFAR10' object has no attribute 'T'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m train_dataset, test_dataset, num_classes, num_training_samples, num_testing_samples \u001B[38;5;241m=\u001B[39m \u001B[43minput_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcifar10\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mnoise_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minstance\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mnoise_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m model \u001B[38;5;241m=\u001B[39m res_cifar\u001B[38;5;241m.\u001B[39mresnet18(pretrained\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m param \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mparameters():\n",
      "File \u001B[0;32m~/PycharmProjects/HOC/data/datasets.py:54\u001B[0m, in \u001B[0;36minput_dataset\u001B[0;34m(dataset, noise_type, noise_ratio, transform, noise_file)\u001B[0m\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28mprint\u001B[39m(train_dataset)\n\u001B[1;32m     53\u001B[0m     \u001B[38;5;66;03m# train_dataset.T\u001B[39;00m\n\u001B[0;32m---> 54\u001B[0m     T \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m dataset \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcifar100\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     57\u001B[0m     train_dataset \u001B[38;5;241m=\u001B[39m CIFAR100(root\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./data/\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     58\u001B[0m                              download\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     59\u001B[0m                              train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     63\u001B[0m                              noise_file\u001B[38;5;241m=\u001B[39mnoise_file\n\u001B[1;32m     64\u001B[0m                              )\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'CIFAR10' object has no attribute 'T'"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset, num_classes, num_training_samples, num_testing_samples = input_dataset('cifar10',noise_type=\"instance\",noise_ratio=0.2)\n",
    "model = res_cifar.resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "model.to(\"mps\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataloader_EF = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                      batch_size=128,\n",
    "                                                      shuffle=True,\n",
    "                                                      num_workers=2,\n",
    "                                                      drop_last=False)\n",
    "# model.to(\"mps\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "\n",
    "def count_real_high(KINDS, T, P, mode, _device = 'cpu'):\n",
    "    # time1 = time.time()\n",
    "    P = P.reshape((KINDS, 1))\n",
    "    p_real = [[] for _ in range(4)]\n",
    "\n",
    "    p_real[0] = torch.mm(T.transpose(0, 1), P).transpose(0, 1)\n",
    "    #print(p_real[0].shape)\n",
    "    # p_real[2] = torch.zeros((KINDS, KINDS, KINDS)).to(_device)\n",
    "    p_real[2] = torch.zeros((KINDS, KINDS, KINDS))\n",
    "    p_real[3] = torch.zeros((KINDS, KINDS, KINDS,KINDS))\n",
    "\n",
    "    temp33 = torch.tensor([])\n",
    "    for i in range(KINDS):\n",
    "        Ti = torch.cat((T[:, i:], T[:, :i]), 1)\n",
    "        temp2 = torch.mm((T * Ti).transpose(0, 1), P)#T * R1 * P\n",
    "        p_real[1] = torch.cat([p_real[1], temp2], 1) if i != 0 else temp2 #P real[preal,  T * R1 * P]\n",
    "\n",
    "        for j in range(KINDS):\n",
    "            Tj = torch.cat((T[:, j:], T[:, :j]), 1)\n",
    "            temp3 = torch.mm((T * Ti * Tj).transpose(0, 1), P)\n",
    "            temp33 = torch.cat([temp33, temp3], 1) if j != 0 else temp3\n",
    "\n",
    "\n",
    "            for k in range(KINDS):\n",
    "                Tk = torch.cat((T[:, k:], T[:, :k]), 1)\n",
    "                temp4 = torch.mm((T * Ti * Tj*Tk).transpose(0, 1), P)\n",
    "                temp44 = torch.cat([temp44, temp4], 1) if k != 0 else temp4\n",
    "            t4 = []\n",
    "\n",
    "            for p4 in range(KINDS):\n",
    "                t4 = torch.cat((temp44[p4, KINDS - p4:], temp44[p4, :KINDS - p4]))\n",
    "                temp44[p4] = t4\n",
    "\n",
    "            for r in range(KINDS):\n",
    "                p_real[3][r][(i+r+KINDS)%KINDS][(i+r+j+KINDS)%KINDS] = temp44[r]\n",
    "\n",
    "\n",
    "        # adjust the order of the output (N*N*N), keeping consistent with p_estimate\n",
    "        t3 = []\n",
    "        for p3 in range(KINDS):\n",
    "            t3 = torch.cat((temp33[p3, KINDS - p3:], temp33[p3, :KINDS - p3]))\n",
    "            temp33[p3] = t3\n",
    "        for r in range(KINDS):\n",
    "            p_real[2][r][(i+r+KINDS)%KINDS] = temp33[r]\n",
    "\n",
    "\n",
    "    temp = []       # adjust the order of the output (N*N), keeping consistent with p_estimate\n",
    "    for p1 in range(KINDS):\n",
    "        temp = torch.cat((p_real[1][p1, KINDS-p1:], p_real[1][p1, :KINDS-p1]))\n",
    "        p_real[1][p1] = temp\n",
    "    return p_real\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def func_high(KINDS, p_estimate, T_out, P_out, N,step, LOCAL, _device):\n",
    "    eps = 1e-2\n",
    "    eps2 = 1e-8\n",
    "    eps3 = 1e-5\n",
    "    loss = torch.tensor(0.0).to(_device)       # define the loss\n",
    "\n",
    "    P = smp(P_out)\n",
    "    T = smt(T_out)\n",
    "\n",
    "    mode = random.randint(0, KINDS-1)\n",
    "    mode = -1\n",
    "    # Borrow p_ The calculation method of real is to calculate the temporary values of T and P at this time: N, N*N, N*N*N\n",
    "    p_temp = count_real_high(KINDS, T.to(torch.device(\"cpu\")), P.to(torch.device(\"cpu\")), mode, _device)\n",
    "\n",
    "    weight = [1.0,1.0,.0,1.0]\n",
    "    # weight = [2.0,1.0,1.0]\n",
    "    order = [0,1,3]\n",
    "    for j in range(4):  # || P1 || + || P2 || + || P3 ||\n",
    "        p_temp[j] = p_temp[j].to(_device)\n",
    "        loss += weight[j] * torch.norm(p_estimate[j] - p_temp[j]) #/ np.sqrt(N**j)\n",
    "\n",
    "    if step > 100 and LOCAL and KINDS != 100:\n",
    "        loss += torch.mean(torch.log(P+eps))/10\n",
    "\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calc_func_high(KINDS, p_estimate, LOCAL, _device, max_step = 501, T0=None, p0 = None, lr = 0.1):\n",
    "\n",
    "    N = KINDS\n",
    "    eps = 1e-8\n",
    "    if T0 is None:\n",
    "        T = 5 * torch.eye(N) - torch.ones((N,N))\n",
    "    else:\n",
    "        T = T0\n",
    "\n",
    "    if p0 is None:\n",
    "        P = torch.ones((N, 1), device = None) / N + torch.rand((N,1), device = None)*0.1     # Pï¼š0-9 distribution\n",
    "    else:\n",
    "        P = p0\n",
    "\n",
    "    T = T.to(_device)\n",
    "    P = P.to(_device)\n",
    "    p_estimate = [item.to(_device) for item in p_estimate]\n",
    "    print(f'using {_device} to solve equations')\n",
    "\n",
    "    T.requires_grad = True\n",
    "    P.requires_grad = True\n",
    "\n",
    "    optimizer = torch.optim.Adam([T, P], lr = lr)\n",
    "\n",
    "    # train\n",
    "    loss_min = 100.0\n",
    "    T_rec = torch.zeros_like(T)\n",
    "    P_rec = torch.zeros_like(P)\n",
    "\n",
    "    time1 = time.time()\n",
    "    for step in range(max_step):\n",
    "        if step:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        loss = func_high(KINDS, p_estimate, T, P, N,step, LOCAL, _device)\n",
    "        if loss < loss_min and step > 5:\n",
    "            loss_min = loss.detach()\n",
    "            T_rec = T.detach()\n",
    "            P_rec = P.detach()\n",
    "        if step % 100 == 0:\n",
    "            print('loss {}'.format(loss))\n",
    "            print(f'step: {step}  time_cost: {time.time() - time1}')\n",
    "            print(f'T {np.round(smt(T.cpu()).detach().numpy()*100,1)}', flush=True)\n",
    "            print(f'P {np.round(smp(P.cpu().view(-1)).detach().numpy()*100,1)}', flush=True)\n",
    "            time1 = time.time()\n",
    "\n",
    "    return loss_min, smt(T_rec).detach(), smp(P_rec).detach(), T_rec.detach()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "record = [[] for _ in range(num_classes)]\n",
    "for i_batch, (feature, label, index) in enumerate(train_dataloader_EF):\n",
    "    feature = feature.to(\"mps\")\n",
    "    label = label.to(\"mps\")\n",
    "    extracted_feature, _ = model(feature)\n",
    "    for i in range(extracted_feature.shape[0]):\n",
    "        record[label[i]].append({'feature': extracted_feature[i].detach().cpu(), 'index': index[i]})\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def count_y(KINDS, feat_cord, label, cluster_sum):\n",
    "    # feat_cord = torch.tensor(final_feat)\n",
    "    cnt = [[] for _ in range(4)]\n",
    "    cnt[0] = torch.zeros(KINDS)\n",
    "    cnt[1] = torch.zeros(KINDS, KINDS)\n",
    "    cnt[2] = torch.zeros(KINDS, KINDS, KINDS)\n",
    "    cnt[3] = torch.zeros(KINDS, KINDS, KINDS,KINDS)\n",
    "    feat_cord = feat_cord.cpu().numpy()\n",
    "    dist = distCosine(feat_cord, feat_cord)\n",
    "    max_val = np.max(dist)\n",
    "    am = np.argmin(dist,axis=1)\n",
    "    for i in range(cluster_sum):\n",
    "        dist[i][am[i]] = 10000.0 + max_val\n",
    "    min_dis_id = np.argmin(dist,axis=1)\n",
    "    for i in range(cluster_sum):\n",
    "        dist[i][min_dis_id[i]] = 10000.0 + max_val\n",
    "    min_dis_id2 = np.argmin(dist,axis=1)\n",
    "    for i in range(cluster_sum):\n",
    "        dist[i][min_dis_id2[i]] = 10000.0 + max_val\n",
    "    min_dis_id3 = np.argmin(dist,axis=1)\n",
    "    for x1 in range(cluster_sum):\n",
    "        cnt[0][label[x1]] += 1\n",
    "        cnt[1][label[x1]][label[min_dis_id[x1]]] += 1\n",
    "        cnt[2][label[x1]][label[min_dis_id[x1]]][label[min_dis_id2[x1]]] += 1\n",
    "        cnt[3][label[x1]][label[min_dis_id[x1]]][label[min_dis_id2[x1]]][label[min_dis_id3[x1]]] += 1\n",
    "\n",
    "    return cnt\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_T_global_high(num_class, record, max_step=501, T0=None, p0=None, lr=0.1, NumTest=50, all_point_cnt=15000):\n",
    "    total_len = sum([len(a) for a in record])\n",
    "    origin_trans = torch.zeros(total_len, record[0][0]['feature'].shape[0])\n",
    "    origin_label = torch.zeros(total_len).long()\n",
    "    cnt, lb = 0, 0\n",
    "    for item in record:\n",
    "        for i in item:\n",
    "            origin_trans[cnt] = i['feature']\n",
    "            origin_label[cnt] = lb\n",
    "            cnt += 1\n",
    "        lb += 1\n",
    "    data_set = {'feature': origin_trans, 'noisy_label': origin_label}\n",
    "\n",
    "    # Build Feature Clusters --------------------------------------\n",
    "    KINDS = num_class\n",
    "    # NumTest = 50\n",
    "    # all_point_cnt = 15000\n",
    "\n",
    "    p_estimate = [[] for _ in range(4)]\n",
    "    p_estimate[0] = torch.zeros(KINDS)\n",
    "    p_estimate[1] = torch.zeros(KINDS, KINDS)\n",
    "\n",
    "    p_estimate[2] = torch.zeros(KINDS, KINDS, KINDS)\n",
    "    p_estimate[3] = torch.zeros(KINDS, KINDS, KINDS,KINDS)\n",
    "    p_estimate_rec = torch.zeros(NumTest, 3)\n",
    "    for idx in range(NumTest):\n",
    "        print(idx, flush=True,end=\" \")\n",
    "        # global\n",
    "        sample = np.random.choice(range(data_set['feature'].shape[0]), all_point_cnt, replace=False)\n",
    "        # final_feat, noisy_label = get_feat_clusters(data_set, sample)\n",
    "        final_feat = data_set['feature'][sample]\n",
    "        noisy_label = data_set['noisy_label'][sample]\n",
    "        cnt_y_3 = count_y(KINDS, final_feat, noisy_label, all_point_cnt)\n",
    "        for i in range(4):\n",
    "            cnt_y_3[i] /= all_point_cnt\n",
    "            p_estimate[i] = p_estimate[i] + cnt_y_3[i] if idx != 0 else cnt_y_3[i]\n",
    "\n",
    "    for j in range(4):\n",
    "        p_estimate[j] = p_estimate[j] / NumTest\n",
    "\n",
    "\n",
    "    loss_min, E_calc, P_calc, T_init = calc_func_high(KINDS, p_estimate, False, \"mps\", max_step, T0, p0, lr=lr)\n",
    "\n",
    "    E_calc = E_calc.cpu().numpy()\n",
    "    T_init = T_init.cpu().numpy()\n",
    "    return E_calc, T_init\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_estimate_T, _ = get_T_global_high(num_class=num_classes,record=record,max_step=1500, lr=0.1, NumTest=50)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.rint(new_estimate_T*100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[11., 12., 13.],\n         [ 0.,  0.,  0.],\n         [ 0.,  0.,  0.]],\n\n        [[ 0.,  0.,  0.],\n         [23., 21., 22.],\n         [ 0.,  0.,  0.]],\n\n        [[ 0.,  0.,  0.],\n         [ 0.,  0.,  0.],\n         [32., 33., 31.]]])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = np.array([[11,12,13],\n",
    "              [21,22,23],\n",
    "              [31,32,33]])\n",
    "T = torch.from_numpy(T)\n",
    "t3 = []\n",
    "p_real =  torch.zeros((3, 3, 3))\n",
    "for p3 in range(3):\n",
    "    t3 = torch.cat((T[p3, 3 - p3:], T[p3, :3 - p3]))\n",
    "    T[p3] = t3\n",
    "for r in range(3):\n",
    "    p_real[r][(0 + r + 3) % 3] = T[r]\n",
    "p_real"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
